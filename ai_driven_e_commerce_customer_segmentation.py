# -*- coding: utf-8 -*-
"""AI-Driven_E-Commerce_Customer_Segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hIdKkFQFNur3BBf86Jiv0GYO4tg4ohIF
"""

import pandas as pd
df=pd.read_excel('/content/online_retail.xlsx')

df.head()

df = df.dropna(subset=['CustomerID'])

from datetime import datetime
snapshot_date = df['InvoiceDate'].max() + pd.Timedelta(days=1)
rfm = df.groupby('CustomerID').agg({
    'InvoiceDate': lambda x: (snapshot_date - x.max()).days,  # Recency
    'InvoiceNo': 'nunique',                                   # Frequency
    'UnitPrice': lambda x: (x * df.loc[x.index, 'Quantity']).sum()  # Monetary
}).rename(columns={'InvoiceDate': 'Recency', 'InvoiceNo': 'Frequency', 'UnitPrice': 'Monetary'})

!pip install pycaret
from pycaret.clustering import *
exp = setup(rfm, normalize=True, session_id=123)

from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
rfm_scaled = scaler.fit_transform(rfm)

kmeans = KMeans(n_clusters=4, random_state=42)
rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)

from sklearn.metrics import silhouette_score
for n in range(2, 6):
    kmeans = KMeans(n_clusters=n, random_state=42)
    labels = kmeans.fit_predict(rfm_scaled)
    print(f"Silhouette Score for {n} clusters: {silhouette_score(rfm_scaled, labels)}")

!pip install pytorch-lightning
import pytorch_lightning as pl
import torch
import torch.nn as nn

class Autoencoder(pl.LightningModule):
    def __init__(self, input_dim=4, hidden_dim=10, latent_dim=2): # Change input_dim to 4
        super().__init__()
        self.encoder = nn.Sequential(nn.Linear(input_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, latent_dim))
        self.decoder = nn.Sequential(nn.Linear(latent_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, input_dim))

    def forward(self, x):
        latent = self.encoder(x)
        return self.decoder(latent)

    def training_step(self, batch, batch_idx):
        x = batch
        recon = self(x)
        loss = nn.functional.mse_loss(recon, x)
        return loss

    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=1e-3)

model = Autoencoder()
trainer = pl.Trainer(max_epochs=20)
trainer.fit(model, torch.utils.data.DataLoader(torch.tensor(rfm_scaled, dtype=torch.float32), batch_size=32))

with torch.no_grad():
    latent_features = model.encoder(torch.tensor(rfm_scaled, dtype=torch.float32)).numpy()
rfm['DeepCluster'] = KMeans(n_clusters=4).fit_predict(latent_features)

!pip install shap
import shap
explainer = shap.KernelExplainer(kmeans.predict, rfm_scaled)
shap_values = explainer.shap_values(rfm_scaled[:100])  # Sample for speed
shap.summary_plot(shap_values, rfm.columns)

import plotly.express as px
fig = px.scatter_3d(rfm, x='Recency', y='Frequency', z='Monetary', color='Cluster', title='Customer Segments')
fig.show()

rfm_old = rfm.copy()

rfm_old.to_csv('rfm_old.csv', index=False)
print("Old rfm saved to 'rfm_old.csv'")

# Simulate new data arriving
# Replace ... with a valid data structure like a dictionary or list
# Here's an example using a dictionary:
new_data = pd.DataFrame({
    'Recency': [10, 20, 30],
    'Frequency': [2, 3, 1],
    'Monetary': [100, 250, 50]
})
rfm = pd.concat([rfm, new_data], ignore_index=True) #ignore_index=True to avoid duplicate indices
rfm_scaled = scaler.fit_transform(rfm[['Recency', 'Frequency', 'Monetary']])
rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)

import google.generativeai as genai

# Configure the Gemini API with your API key
genai.configure(api_key='AIzaSyDf4gWtxTpPxFBmGc6XE4jxUVs6qzxYS90')

# Specify the Gemini model
# Use 'gemini-1.5-flash' or 'models/gemini-1.5-flash' instead of 'gemini-pro'
model = genai.GenerativeModel('gemini-1.5-flash')

# Define the prompt
prompt = "Write a discount email for VIP customers."

# Generate the response
response = model.generate_content(prompt)

# Print the generated text
print(response.text)